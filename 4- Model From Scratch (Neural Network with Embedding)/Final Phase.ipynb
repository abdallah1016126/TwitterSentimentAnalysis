{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import math\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre = pd.read_csv(\"final_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre.rename(columns={\"polarity\":\"Polarity\", \"words\":\"Words\"}, inplace=True)\n",
    "for col in df_pre.columns:\n",
    "    if col!='Words':\n",
    "        df_pre[col] = df_pre[col].astype(np.int8)\n",
    "df_pre['Words'] = df_pre['Words'].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Words</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>h_00</th>\n",
       "      <th>...</th>\n",
       "      <th>h_14</th>\n",
       "      <th>h_15</th>\n",
       "      <th>h_16</th>\n",
       "      <th>h_17</th>\n",
       "      <th>h_18</th>\n",
       "      <th>h_19</th>\n",
       "      <th>h_20</th>\n",
       "      <th>h_21</th>\n",
       "      <th>h_22</th>\n",
       "      <th>h_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'awww': 1, 'bummer': 1, 'shoulda': 1, 'david'...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>{'upset': 1, 'notupdate': 1, 'facebook': 1, 't...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>{'dive': 1, 'many': 1, 'time': 1, 'ball': 1, '...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>{'whole': 1, 'body': 1, 'feel': 1, 'itchy': 1,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>{'mad': 1, 'notsee': 1}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Polarity                                              Words  Fri  Mon  Sat  \\\n",
       "0         0  {'awww': 1, 'bummer': 1, 'shoulda': 1, 'david'...    0    1    0   \n",
       "1         0  {'upset': 1, 'notupdate': 1, 'facebook': 1, 't...    0    1    0   \n",
       "2         0  {'dive': 1, 'many': 1, 'time': 1, 'ball': 1, '...    0    1    0   \n",
       "3         0  {'whole': 1, 'body': 1, 'feel': 1, 'itchy': 1,...    0    1    0   \n",
       "4         0                            {'mad': 1, 'notsee': 1}    0    1    0   \n",
       "\n",
       "   Sun  Thu  Tue  Wed  h_00  ...  h_14  h_15  h_16  h_17  h_18  h_19  h_20  \\\n",
       "0    0    0    0    0     0  ...     0     0     0     0     0     0     0   \n",
       "1    0    0    0    0     0  ...     0     0     0     0     0     0     0   \n",
       "2    0    0    0    0     0  ...     0     0     0     0     0     0     0   \n",
       "3    0    0    0    0     0  ...     0     0     0     0     0     0     0   \n",
       "4    0    0    0    0     0  ...     0     0     0     0     0     0     0   \n",
       "\n",
       "   h_21  h_22  h_23  \n",
       "0     0     1     0  \n",
       "1     0     1     0  \n",
       "2     0     1     0  \n",
       "3     0     1     0  \n",
       "4     0     1     0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6839"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words = df_pre.iloc[:,1]\n",
    "all_words = {}\n",
    "i = 0\n",
    "for dic in df_pre['Words']:\n",
    "    for word in dic:\n",
    "        if word not in all_words:\n",
    "            all_words[word] = i\n",
    "            i += 1\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Words</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>h_00</th>\n",
       "      <th>...</th>\n",
       "      <th>h_14</th>\n",
       "      <th>h_15</th>\n",
       "      <th>h_16</th>\n",
       "      <th>h_17</th>\n",
       "      <th>h_18</th>\n",
       "      <th>h_19</th>\n",
       "      <th>h_20</th>\n",
       "      <th>h_21</th>\n",
       "      <th>h_22</th>\n",
       "      <th>h_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'even': 1, 'sound': 1, 'like': 1, 'mind': 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'sunshine': 2, 'super': 1, 'til': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'also': 1, 'check': 1, 'plugin': 1, 'tweet': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'watch': 1}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'feel': 1, 'sigh': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Polarity                                              Words  Fri  Mon  Sat  \\\n",
       "0         0  {'even': 1, 'sound': 1, 'like': 1, 'mind': 1, ...    0    1    0   \n",
       "1         1              {'sunshine': 2, 'super': 1, 'til': 1}    1    0    0   \n",
       "2         1  {'also': 1, 'check': 1, 'plugin': 1, 'tweet': ...    0    1    0   \n",
       "3         1                                       {'watch': 1}    0    0    0   \n",
       "4         1                             {'feel': 1, 'sigh': 1}    1    0    0   \n",
       "\n",
       "   Sun  Thu  Tue  Wed  h_00  ...  h_14  h_15  h_16  h_17  h_18  h_19  h_20  \\\n",
       "0    0    0    0    0     0  ...     0     0     0     0     0     0     0   \n",
       "1    0    0    0    0     0  ...     0     0     0     0     0     0     0   \n",
       "2    0    0    0    0     0  ...     0     0     0     0     0     0     0   \n",
       "3    1    0    0    0     0  ...     0     0     0     0     0     0     0   \n",
       "4    0    0    0    0     0  ...     0     0     0     0     0     0     0   \n",
       "\n",
       "   h_21  h_22  h_23  \n",
       "0     0     0     0  \n",
       "1     0     0     0  \n",
       "2     0     0     0  \n",
       "3     0     0     0  \n",
       "4     0     0     0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_pre = shuffle(df_pre)\n",
    "df_pre.reset_index(inplace=True, drop=True)\n",
    "df_pre.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets the hour\n",
    "hour_col = np.argmax(np.array(df_pre.iloc[:,9:]), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Words</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'even': 1, 'sound': 1, 'like': 1, 'mind': 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>{'sunshine': 2, 'super': 1, 'til': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>{'also': 1, 'check': 1, 'plugin': 1, 'tweet': ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'watch': 1}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>{'feel': 1, 'sigh': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Polarity                                              Words  Fri  Mon  Sat  \\\n",
       "0         0  {'even': 1, 'sound': 1, 'like': 1, 'mind': 1, ...    0    1    0   \n",
       "1         1              {'sunshine': 2, 'super': 1, 'til': 1}    1    0    0   \n",
       "2         1  {'also': 1, 'check': 1, 'plugin': 1, 'tweet': ...    0    1    0   \n",
       "3         1                                       {'watch': 1}    0    0    0   \n",
       "4         1                             {'feel': 1, 'sigh': 1}    1    0    0   \n",
       "\n",
       "   Sun  Thu  Tue  Wed      Hour  \n",
       "0    0    0    0    0  0.173913  \n",
       "1    0    0    0    0  0.391304  \n",
       "2    0    0    0    0  0.217391  \n",
       "3    1    0    0    0  0.478261  \n",
       "4    0    0    0    0  0.086957  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_pre.iloc[:,:9]\n",
    "df['Hour'] = hour_col / 23\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1496338, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X_train = df.iloc[:1000000,1:]\n",
    "y_train = df.iloc[:1000000,0]\n",
    "X_test = df.iloc[1000000:1486000,1:]\n",
    "y_test = df.iloc[1000000:1486000,0]\n",
    "X_valid = df.iloc[1486000:,1:]\n",
    "y_valid = df.iloc[1486000:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam():\n",
    "    def __init__(self,lr=0.01,beta1=0.9,beta2=0.999):\n",
    "            self.alpha = lr\n",
    "            self.beta1 = beta1\n",
    "            self.beta2 = beta2\n",
    "            self.v = []\n",
    "            self.s = []\n",
    "\n",
    "    def init_params(self,layers):\n",
    "        self.v.clear()\n",
    "        self.s.clear()\n",
    "        for layer in layers:\n",
    "            w = np.zeros_like(layer.W)\n",
    "            b = np.zeros_like(layer.b)\n",
    "            self.v.append([w,b])\n",
    "            self.s.append([w,b])\n",
    "\n",
    "    def update(self,layers,N):\n",
    "        for i in range(len(layers)):\n",
    "            self.v[i][0] = self.beta1 * self.v[i][0] + (1-self.beta1) * layers[i].dW\n",
    "            self.v[i][1] = self.beta1 * self.v[i][1] + (1-self.beta1) * layers[i].db\n",
    "\n",
    "            self.s[i][0] = self.beta2 * self.s[i][0] + (1-self.beta2) * np.square(layers[i].dW)\n",
    "            self.s[i][1] = self.beta2 * self.s[i][1] + (1-self.beta2) * np.square(layers[i].db)\n",
    "\n",
    "            deltaW = (-1 * self.alpha * self.v[i][0]) / (np.sqrt(self.s[i][0] + 0.001))\n",
    "            deltab = (-1 * self.alpha * self.v[i][1]) / (np.sqrt(self.s[i][1] + 0.001))\n",
    "\n",
    "            layers[i].W = layers[i].W + deltaW/N\n",
    "            layers[i].b = layers[i].b + deltab/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer():\n",
    "    def __init__(self,n_output,n_input,type_, activation=\"sigmoid\",parameter_initializer=\"uniform\",target=None):\n",
    "        self.n_output = n_output\n",
    "        self.n_input = n_input\n",
    "        self.activation = self.get_activations()[activation]\n",
    "        self.act_name = activation\n",
    "        self.target = target\n",
    "        self.type = type_\n",
    "        \n",
    "        # Trying different weight initializations\n",
    "        if parameter_initializer == \"he_normal\":\n",
    "            self.W = np.random.randn(self.n_output,self.n_input)*np.sqrt(2/self.n_input)\n",
    "            self.b = np.random.randn(self.n_output,1)*np.sqrt(2/self.n_input)\n",
    "        elif parameter_initializer == \"normal\":\n",
    "            self.W = np.random.randn(0, 1, (self.n_output,self.n_input))\n",
    "            self.b = np.random.randn(0, 1, (self.n_output,1))\n",
    "        elif parameter_initializer == \"uniform\":\n",
    "            self.W = np.random.uniform(-0.05,0.05,(self.n_output,self.n_input))\n",
    "            self.b = np.random.uniform(-0.05,0.05,(self.n_output,1))\n",
    "            \n",
    "        self.dW = np.zeros_like(self.W)\n",
    "        self.db = np.zeros_like(self.b)\n",
    "\n",
    "        self.Z = None\n",
    "        self.X = None\n",
    "       \n",
    "    def _onehot(self, a, M):\n",
    "        b = np.zeros( (a.size, M), dtype = 'int')\n",
    "        b[ np.arange(a.size), a] = 1\n",
    "        return b.T\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        return (1/(1+np.exp(-1*z)))\n",
    "\n",
    "    def _diff_sigmoid(self, z):\n",
    "        sig = self.sigmoid(z)\n",
    "        return sig * (1-sig)\n",
    "\n",
    "    def softmax(self, z):\n",
    "        exp = np.exp(z)\n",
    "        tot = exp.sum(axis=0)\n",
    "        t = exp/tot\n",
    "        return t\n",
    "\n",
    "    def _diff_softmax(self,z,y):\n",
    "        yhat_r = self.softmax(z)\n",
    "        onehotY = self._onehot(y,z.shape[0])\n",
    "        one_yi = onehotY *-1*(1-yhat_r)\n",
    "        z = (1-onehotY)*yhat_r\n",
    "        return one_yi +z\n",
    "\n",
    "    def get_activations(self):\n",
    "        return {\"softmax\":self.softmax, \"sigmoid\":self.sigmoid}\n",
    "\n",
    "    def get_activations_diff(self):\n",
    "        return {\"softmax\":self._diff_softmax, \"sigmoid\":self._diff_sigmoid}\n",
    "\n",
    "    def get_params(self):\n",
    "        return [self.W, self.b]\n",
    "\n",
    "    def zeroing_delta(self):\n",
    "        self.dW = np.zeros_like(self.W)\n",
    "        self.db = np.zeros_like(self.b)\n",
    "\n",
    "    def _set_target(self, t):\n",
    "        self.target = t\n",
    "\n",
    "    def forward(self,input_, t = False):\n",
    "        self.X = input_\n",
    "        z = np.dot(self.W, self.X)+self.b\n",
    "        A = self.activation(z)\n",
    "        self.Z = z\n",
    "        \n",
    "        return A\n",
    "    \n",
    "    def backward(self,input_):\n",
    "        if self.act_name == \"softmax\":\n",
    "            f_dash = self._diff_softmax(self.Z,self.target)\n",
    "        else:\n",
    "            f_dash = self.get_activations_diff()[self.act_name](self.Z)\n",
    "\n",
    "        e = np.ones((self.X.shape[1],1))\n",
    "        bet = input_ * f_dash\n",
    "        \n",
    "        self.dW = self.dW + np.dot(bet,self.X.T)\n",
    "        self.db = self.db + np.dot(bet,e)\n",
    "        \n",
    "        return np.dot(self.W.T, bet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self,all_words,optimizer):\n",
    "        self.layers = []\n",
    "        self.all_words = all_words\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    \n",
    "    def SoftmaxLogLikelihood(self,y,yhat):\n",
    "        onehotY= self._onehot(y,yhat.shape[0])\n",
    "        yhat_r = np.max(onehotY*yhat, axis=0,keepdims=True)\n",
    "        return (1/(y.shape[0]))*-1*np.sum(np.log(yhat_r))\n",
    "    \n",
    "    def _onehot(self, a, M):\n",
    "        b = np.zeros( (a.size, M), dtype = 'int')\n",
    "        b[ np.arange(a.size), a] = 1\n",
    "        return b.T\n",
    "        \n",
    "    def transform_words(self, x):\n",
    "        encoding = np.zeros(len(self.all_words))\n",
    "        i = 0\n",
    "        for word in x:\n",
    "            if word in self.all_words:\n",
    "                encoding[self.all_words[word]] = 1\n",
    "        return encoding.astype(np.int8)\n",
    "    \n",
    "    def add(self,layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def forward(self,input_):\n",
    "        X_words = input_[8:,:]\n",
    "        X_time = input_[:8,:]\n",
    "        \n",
    "        layer_index = 0\n",
    "        while layer_index < len(self.layers):\n",
    "            layer = self.layers[layer_index]\n",
    "            if layer.type != \"word_embedding\":\n",
    "                break\n",
    "            layer_index += 1\n",
    "            X_words = layer.forward(X_words)\n",
    "                    \n",
    "        a = np.concatenate((X_words, X_time), axis=0)\n",
    "        while layer_index < len(self.layers):\n",
    "            layer = self.layers[layer_index]\n",
    "            t = False\n",
    "            a = layer.forward(a, t)\n",
    "            layer_index += 1\n",
    "\n",
    "        return a\n",
    "    \n",
    "    def backward(self,input_):\n",
    "        gd = input_\n",
    "        layer_index = len(self.layers) - 1\n",
    "        \n",
    "        while layer_index>=0:\n",
    "            layer=self.layers[layer_index]\n",
    "            if layer.type != 'full':\n",
    "                break\n",
    "            layer_index -=1\n",
    "            gd = layer.backward(gd)\n",
    "            \n",
    "        nout_time = 8\n",
    "        gd_words = gd[:gd.shape[0] - nout_time,:]\n",
    "        gd_time = gd[gd.shape[0]-nout_time:,:]\n",
    "    \n",
    "        while layer_index >= 0:\n",
    "            layer = self.layers[layer_index]\n",
    "            layer_index -= 1\n",
    "            gd_words = layer.backward(gd_words)\n",
    "            \n",
    "            \n",
    "    def zeroing(self):\n",
    "        for layer in self.layers:\n",
    "            layer.zeroing_delta()\n",
    "            \n",
    "\n",
    "    def batch(self,x,y,bs):\n",
    "        x = x.copy()\n",
    "        y = y.copy()\n",
    "        rem = x.shape[0] % bs\n",
    "\n",
    "        for i in range(0,x.shape[0],bs):\n",
    "            yield (x[i:i+bs],y[i:i+bs])\n",
    "        \n",
    "        if rem !=0:\n",
    "            yield (x[x.shape[0]-rem:],y[x.shape[0]-rem:] )\n",
    "\n",
    "    def fit(self,train_data,validation_data=None, batch_size=32, epochs=5):\n",
    "        x_train = train_data[0]\n",
    "        y_train = train_data[1]\n",
    "        no_of_batches_train = np.ceil(x_train.shape[0]/batch_size)\n",
    "       \n",
    "        if validation_data:\n",
    "            x_valid = validation_data[0]\n",
    "            y_valid = validation_data[1]\n",
    "        \n",
    "        for i in range(epochs):\n",
    "            self.optimizer.init_params(self.layers)\n",
    "            print()\n",
    "            print(\"Epoch {}/{}\".format(i+1,epochs))\n",
    "            j = 0\n",
    "            k = 0\n",
    "            data = self.batch(x_train,y_train,batch_size)\n",
    "            losses = []\n",
    "            \n",
    "            for temp_x,temp_y in data:\n",
    "                k += 1\n",
    "                curr_x = temp_x.copy()\n",
    "                curr_y = temp_y.copy()\n",
    "                \n",
    "                word_encodings = []\n",
    "                for dic in curr_x[:,0]:\n",
    "                    word_encodings.append(self.transform_words(dic))\n",
    "                words = np.array(word_encodings)\n",
    "                curr_x = curr_x[:,1:].astype(np.int8)\n",
    "                curr_x = np.concatenate((curr_x, words), axis=1)\n",
    "    \n",
    "                curr_x = curr_x.T\n",
    "                curr_y = curr_y.T\n",
    "                y_hat = self.forward(curr_x)            \n",
    "                \n",
    "                # knowing that the loss is SoftmaxLogLikelihood\n",
    "                self.layers[-1]._set_target(curr_y)\n",
    "                self.backward(1)\n",
    "                \n",
    "                if int(0.1 * no_of_batches_train) == (k):\n",
    "                    print(\"=\", end = \"\")\n",
    "                    k = 0\n",
    "                \n",
    "                losses.append(self.SoftmaxLogLikelihood(curr_y,y_hat))\n",
    "\n",
    "                if j == no_of_batches_train-1:\n",
    "                    loss = sum(losses) / len(losses)\n",
    "                    print()\n",
    "                    print(\"loss: {}....\".format(loss),end=\" \")\n",
    "\n",
    "                if batch_size == 1:\n",
    "                    N = train_data[0].shape[0]\n",
    "                else:\n",
    "                    N = curr_x.shape[-1]\n",
    "                \n",
    "                self.optimizer.update(self.layers,N)\n",
    "                self.zeroing()\n",
    "                j += 1 \n",
    "            \n",
    "            ###\n",
    "            if validation_data:\n",
    "                y_hat_val = self.forward(x_valid.T)\n",
    "                loss_val= self.SoftmaxLogLikelihood(y_valid.T,y_hat_val)\n",
    "                print(\"val_loss: {}....\".format(loss_val),end=\" \")\n",
    "            ###\n",
    "\n",
    "    def predict(self,data):\n",
    "        \n",
    "        word_encodings = []\n",
    "        for dic in data[:,0]:\n",
    "            word_encodings.append(self.transform_words(dic))\n",
    "        words = np.array(word_encodings)\n",
    "        data = data[:,1:].astype(np.int8)\n",
    "        data = np.concatenate((data, words), axis = 1)\n",
    "        \n",
    "        y_hat= self.forward(data.T)\n",
    "        return y_hat.T\n",
    "    \n",
    "    \n",
    "    def get_weights(self):\n",
    "        params=[]\n",
    "        for layer in self.layers:\n",
    "            params.append(layer.get_params())\n",
    "        \n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Words</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1486000</th>\n",
       "      <td>{'aww': 1, 'well': 1, 'soon': 1}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486001</th>\n",
       "      <td>{'notwork': 1, 'twitter': 1}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486002</th>\n",
       "      <td>{'think': 1, 'work': 1, 'every': 1, 'pen': 1, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486003</th>\n",
       "      <td>{'seriously': 1, 'lolz': 1, 'want': 1, 'back':...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486004</th>\n",
       "      <td>{'would': 1, 'suggest': 1, 'avoid': 1, 'living...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.347826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496333</th>\n",
       "      <td>{'omg': 1, 'must': 1, 'black': 1, 'bag': 1, 'w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496334</th>\n",
       "      <td>{'girl': 1, 'mirror': 1, 'wait': 1}</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496335</th>\n",
       "      <td>{'grow': 1, 'notsure': 1, 'like': 1}</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496336</th>\n",
       "      <td>{'yes': 1, 'still': 1, 'require': 1, 'lot': 1,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1496337</th>\n",
       "      <td>{'notcrazy': 1, 'see': 1, 'dead': 1, 'baby': 1...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10338 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Words  Fri  Mon  Sat  \\\n",
       "1486000                   {'aww': 1, 'well': 1, 'soon': 1}    0    0    1   \n",
       "1486001                       {'notwork': 1, 'twitter': 1}    0    0    0   \n",
       "1486002  {'think': 1, 'work': 1, 'every': 1, 'pen': 1, ...    0    0    1   \n",
       "1486003  {'seriously': 1, 'lolz': 1, 'want': 1, 'back':...    0    0    0   \n",
       "1486004  {'would': 1, 'suggest': 1, 'avoid': 1, 'living...    0    0    0   \n",
       "...                                                    ...  ...  ...  ...   \n",
       "1496333  {'omg': 1, 'must': 1, 'black': 1, 'bag': 1, 'w...    0    0    0   \n",
       "1496334                {'girl': 1, 'mirror': 1, 'wait': 1}    0    1    0   \n",
       "1496335               {'grow': 1, 'notsure': 1, 'like': 1}    0    0    0   \n",
       "1496336  {'yes': 1, 'still': 1, 'require': 1, 'lot': 1,...    0    0    1   \n",
       "1496337  {'notcrazy': 1, 'see': 1, 'dead': 1, 'baby': 1...    0    0    0   \n",
       "\n",
       "         Sun  Thu  Tue  Wed      Hour  \n",
       "1486000    0    0    0    0  0.826087  \n",
       "1486001    1    0    0    0  0.826087  \n",
       "1486002    0    0    0    0  0.608696  \n",
       "1486003    1    0    0    0  0.217391  \n",
       "1486004    0    1    0    0  0.347826  \n",
       "...      ...  ...  ...  ...       ...  \n",
       "1496333    1    0    0    0  0.913043  \n",
       "1496334    0    0    0    0  0.173913  \n",
       "1496335    0    0    0    1  0.217391  \n",
       "1496336    0    0    0    0  0.434783  \n",
       "1496337    1    0    0    0  0.695652  \n",
       "\n",
       "[10338 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_words( x):\n",
    "    encoding = np.zeros(len(all_words))\n",
    "    i = 0\n",
    "    for word in x:\n",
    "        if word in all_words:\n",
    "            encoding[all_words[word]] = 1\n",
    "    return encoding.astype(np.int8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = np.array(X_valid)\n",
    "word_encodings = []\n",
    "for dic in X_valid[:,0]:\n",
    "    word_encodings.append(transform_words(dic))\n",
    "words = np.array(word_encodings)\n",
    "X_valid = X_valid[:,1:].astype(np.int8)\n",
    "X_valid = np.concatenate((X_valid, words), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "==========\n",
      "loss: 0.6818744551996745.... val_loss: 0.674145952745111.... \n",
      "Epoch 2/10\n",
      "==========\n",
      "loss: 0.6720101423722076.... val_loss: 0.6641497739882841.... \n",
      "Epoch 3/10\n",
      "==========\n",
      "loss: 0.5357949614409435.... val_loss: 0.47229770543566607.... \n",
      "Epoch 4/10\n",
      "==========\n",
      "loss: 0.46621158552217373.... val_loss: 0.45234632050409046.... \n",
      "Epoch 5/10\n",
      "==========\n",
      "loss: 0.45802549273090715.... val_loss: 0.4472202206175892.... \n",
      "Epoch 6/10\n",
      "==========\n",
      "loss: 0.4554143656407107.... val_loss: 0.44537395775983.... \n",
      "Epoch 7/10\n",
      "==========\n",
      "loss: 0.4543027041161438.... val_loss: 0.44457613058885187.... \n",
      "Epoch 8/10\n",
      "==========\n",
      "loss: 0.4536867513421939.... val_loss: 0.4441324675575593.... \n",
      "Epoch 9/10\n",
      "==========\n",
      "loss: 0.45320143116911094.... val_loss: 0.44374132635752384.... \n",
      "Epoch 10/10\n",
      "==========\n",
      "loss: 0.4526415359865113.... val_loss: 0.44321097282326793.... "
     ]
    }
   ],
   "source": [
    "adam = Adam(lr = 0.5)\n",
    "NN = Model(all_words, optimizer=adam)\n",
    "in_words = layer(8, len(all_words), \"word_embedding\")\n",
    "hidden_words = layer(10, 8, \"word_embedding\")\n",
    "full_hidden = layer(4, 18, \"full\")\n",
    "full_out = layer(2, 4, \"full\", activation=\"softmax\")\n",
    "NN.add(in_words)\n",
    "NN.add(hidden_words)\n",
    "NN.add(full_hidden)\n",
    "NN.add(full_out)\n",
    "\n",
    "\n",
    "validationData=(X_valid, y_valid)\n",
    "\n",
    "train_data = (np.array(X_train), np.array(y_train))\n",
    "\n",
    "NN.fit(train_data,validation_data=validationData, batch_size=1000, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([])\n",
    "y = None\n",
    "for i in range(48):\n",
    "    y = NN.predict(np.array(X_test.iloc[i*10000:(i+1)*10000,:]))\n",
    "    y = np.argmax(y, axis = 1)\n",
    "    y_pred = np.concatenate([y_pred, y], axis = 0)\n",
    "    \n",
    "y = NN.predict(np.array(X_test.iloc[480000:,:]))\n",
    "y = np.argmax(y, axis = 1)\n",
    "y_pred = np.concatenate([y_pred, y], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[193686  51690]\n",
      " [ 49166 191458]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79    245376\n",
      "           1       0.79      0.80      0.79    240624\n",
      "\n",
      "    accuracy                           0.79    486000\n",
      "   macro avg       0.79      0.79      0.79    486000\n",
      "weighted avg       0.79      0.79      0.79    486000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cf = confusion_matrix(y_test, y_pred)\n",
    "print(cf)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAD4CAYAAAAeugY9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAg50lEQVR4nO3deXhV1bnH8e8bIlZmEGQKVRTEsbbAFaqtCiiDVgGlCF4FFM11FmsdECtVcWy1ilq9VCigFrAOF8QBoqI4FARqq+JQUiqQAAFk0lqEJO/94yz0CBlOBkiy8vv4rId93rX2XvsovllZe+29zd0REZGaLa2qT0BERCpOyVxEJAJK5iIiEVAyFxGJgJK5iEgE0vd0Bzs2LNdyGdlNw4yTqvoUpBratm2lVfQYZck5+zQ/uML9VRd7PJmLiOxVhQVVfQZVQslcROLihVV9BlVCyVxE4lKoZC4iUuO5RuYiIhEoyK/qM6gSSuYiEhddABURiYCmWUREIqALoCIiNZ8ugIqIxEAjcxGRCBTsqOozqBJK5iISF02ziIhEQNMsIiIR0MhcRCQCGpmLiNR8XqgLoCIiNV8tHZnrtXEiEhcvTL2Uwswmmdk6M/swKfZDM1tgZn8zs8VmdmyIm5mNN7NsM3vfzDon7TPczJaFMjwp3sXMPgj7jDczC/FmZpYV2meZWdPSzlXJXETiUliQeindZKDvLrF7gFvc/YfAzeEzQD+gYyiZwCOQSMzAWKAbcCwwNik5PwJclLTfzr5uAF51947Aq+FziZTMRSQulTgyd/f5wMZdw0CjsN0YWB22+wNTPWEB0MTMWgN9gCx33+jum4AsoG+oa+TuC9zdganAgKRjTQnbU5LixdKcuYjEpQxz5maWSWIUvdMEd59Qym6jgDlm9lsSA+LjQrwtsCqpXU6IlRTPKSIO0NLd14TttUDL0r6LkrmIxKUML6cIibu05L2rS4Cr3f0ZMxsMTAROLuMxUububmZeWjtNs4hIXAoLUy/lMxx4Nmz/mcQ8OEAu0C6pXUaIlRTPKCIOkBemYQh/rivtpJTMRSQq7gUpl3JaDZwYtnsCy8L2LGBYWNXSHdgSpkrmAL3NrGm48NkbmBPqtppZ97CKZRgwM+lYO1e9DE+KF0vTLCISl0pcZ25m04CTgOZmlkNiVcpFwANmlg5s49s59xeBU4Fs4CvgfAB332hmtwGLQrtb3X3nRdVLSayY2Q94KRSAu4CnzGwksAIYXOq5Ji6i7jk7Nizfsx1IjdQw46SqPgWphrZtW2kVPcZ/5j2Wcs7Zr8eFFe6vutDIXETiUkvvAFUyF5G4lGE1S0yUzEUkLnoErohIBDTNIiISASVzEZEIaJpFRCQCugAqIhIBTbOIiERA0ywiIhHQyFxEJAJK5iIiEdjDz5uqrpTMRSQu+VrNIiJS8+kCqIhIBDRnLiISAc2Zi4hEQCNzEZEIKJmLiNR8XlDuFzXXaErmIhIXjcxFRCJQS5cmplX1CYiIVKpCT72Uwswmmdk6M/twl/gVZvaJmS01s3uS4qPNLNvMPjWzPknxviGWbWY3JMXbm9nCEJ9hZnVDfN/wOTvUH1TauSqZi0hcCgtTL6WbDPRNDphZD6A/cIy7Hwn8NsSPAIYAR4Z9fm9mdcysDvAw0A84Ahga2gLcDfzO3TsAm4CRIT4S2BTivwvtSqRkLiJxKShIvZTC3ecDG3cJXwLc5e5fhzbrQrw/MN3dv3b3fwHZwLGhZLv7cnffDkwH+puZAT2Bp8P+U4ABSceaErafBnqF9sVSMi/BTXfcxwmnDWHAuRcXWb9l6xdcOfpWBg67hCEXXsWy5Z9VuM/t27dzza/upN/gCxh60Shy1+QBkLsmjy49+nPW8Ms4a/hl3HLPgxXuS8rn00/fZvHiuSxc+BJvvz17t/ohQwawaNEcFi+ey7x5z3L00YdXuM+6devy+OMPs3TpfObPn8mBB2Z8p75duzZs2PAxo0ZlVrivGq8MI3MzyzSzxUkllX+BhwI/DdMfb5jZf4V4W2BVUrucECsuvj+w2d3zd4l/51ihfktoXywl8xIMOPUUHr1vXLH1f5g6g8M6HsJzUx/hjl/9krvufzTlY+euyWPE5dftFn929lwaNWzAS09N4ryzB3Df7yd9U9eubWuemfIwz0x5mLHXXVG2LyOVqk+fs+nWrR/HH/+z3eo++2wVp5wymK5de3PnneN5+OG7Uj7ugQdmMHfujN3iI0aczebNWzjyyBN48MHHGDdu9Hfq7777ZubMeb3M3yNKZZgzd/cJ7t41qUxIoYd0oBnQHbgWeKq0UfPeoGRegq4/PJrGjRoWW//Pz1bSrfMxABx8YDty1+SxYeMmAJ6f8xpDLrwqjKLHU5Di2tfX3vwL/U89GYDeJ/2UhUv+htfS25NrqgULlrB58xYA3n33Pdq2bf1N3dChA3nzzVksXPgSDz10J2lpqf0vePrpvXniicRv488++yI9ehz/nbrPPlvJxx//oxK/RQ3mhamX8skBnvWEd4FCoDmQC7RLapcRYsXFPweamFn6LnGS9wn1jUP7YpX6N8nMDjOz681sfCjXm1nFf2+MQKcOB/PKG28D8MFHn7Imbx156zbwz89W8vKrb/D4o/fyzJSHSUtLY/bceSkdc936z2l1QHMA0tPr0KB+PTZv2QpA7pq1DBpxGSMuu5Ylf/uwpMPIHuTuzJ79BO+88wIjR55TYtsRI85mbvhv36lTBwYNOp0ePc6kW7d+FBQUMHTowJT6bNOmFTk5qwEoKChg69Yv2H//ptSvX49rrrmE22+/v0LfKSqVuJqlGP8H9AAws0OBusAGYBYwJKxEaQ90BN4FFgEdw8qVuiQuks7yxChtHjAoHHc4MDNszwqfCfWveSmjuhLXmZvZ9cBQEhP274ZwBjDNzKa7e5G/P4Z5p0yA3987jguHDS2pmxrrwvN+zl33/y9nDb+MjoccxGEdD6FOWhoLF/+Njz7JZsjIqwD4+uuvada0CQBXjr6V3NV57MjfwZq89Zw1/DIAzh3cn4Gn9S62rxb7NyXr2ak0adyIpZ8s48rRtzLziUdpUL/+Hv+e8l09e57F6tV5tGixPy+88CSffprNW2+9u1u7E0/8MSNGnE3PnmcB0KPH8fzoR0fz9tvPA7Dfft9j/frEYGvGjAkcdFA76tatS7t2bVi48CUAHn54ElOn/rnYc7nppqt58MGJ/PvfX1X216yxvBJvGjKzacBJQHMzywHGApOASWG54nZgeEi0S83sKeAjIB+4zN0LwnEuB+YAdYBJ7r40dHE9MN3MxgHvARNDfCLwuJllk7gAO6S0cy3tpqGRwJHuvmOXL3gfsBQoMpmHeacJADs2LI92jqBB/fqMG/MLIDFa6zNoBBltW7Hk7x9yRr+TufqS83fbZ/ydNwOJOfMxt9/L5Ifu+U79AS32Z+26DbQ6oAX5+QV8+e+vaNK4EWZG3bp1ATjysI60a9uaz1bmctThh+7hbym7Wr06cVF6/frPmTVrDl27/nC3ZH7UUYfxyCP3cMYZw9i4cTMAZsaTTz7Nr361+yqzs89OXHc78MAM/vCHe+nd++xd+lxLRkYbcnPXUqdOHRo1asjnn2/i2GN/xJlnnsodd4ymceNGFBY627Z9zaOPTtmtj1qjEm/nd/fiRqLnFtP+duD2IuIvAi8WEV9OYrXLrvFtwM/Lcq6lTbMUAm2KiLcOdbXa1i++ZMeOxM+5Z55/mS4/PJoG9evTvesPyXr9LT7ftBlIrHpZvTYvpWP2+El3Zr74CgBzX3+Tbl2OwczYuGnzN/Puq3LXsHLVatolzcXK3lGv3n40aFD/m+1evX7K0qWffqdNu3ZtmDFjAhdcMIrs7H99E583720GDjyVFi0SixKaNm3M97/fllTMnp3Fuecmfhs/88xTef31dwDo1WsQnTodT6dOx/PQQ5O4556Hancih70xzVItlTYyHwW8ambL+HZpzfeBDsDle/C8qoVrx97FovfeZ/PmrfQacC6XjjyP/PBKqrMHnsbyFasYM+5eDDik/YHcOnoUhO0rLhpG5qgxFHoh+6SnM+YXl9KmVctS+zzzZ30Yfdtv6Df4Aho3ashvbkncLLbkbx/y0GOPk56eTlqacfO1l5d4cVb2jJYtWzBjRmLBQ3p6OjNm/B9ZWW9w4YWJgdpjjz3BjTdeRbNmTXnggcRKqPz8Ao4//md88skyfv3r3zJ79hOkpaWxY0c+o0bdxMqVucX2t9PkyTOYNOl+li6dz8aNmxk2LPr//cqvlj6bxUpbKWFmaSR+Ddg5hMgFFu2cCypNzNMsUn4NM06q6lOQamjbtpUVXuL375uHpJxz6t86vcqXFFaWUh+05e6FwIK9cC4iIhVXSx+0pacmikhcIpsLT5WSuYhExfP1cgoRkZpPI3MRkQhozlxEJAIamYuI1HyuZC4iEgFdABURiYBG5iIiEVAyFxGp+Wrry1yUzEUkLhqZi4hEQMlcRKTm83zdNCQiUvPVzlyuZC4icdFNQyIiMVAyFxGJQC2dZinthc4iIjWKF3rKpTRmNsnM1pnZh0XUXWNmbmbNw2czs/Fmlm1m75tZ56S2w81sWSjDk+JdzOyDsM94M7MQb2ZmWaF9lpk1Le1clcxFJCqe7ymXFEwG+u4aNLN2QG9gZVK4H9AxlEzgkdC2GTAW6Ebifcpjk5LzI8BFSfvt7OsG4FV37wi8Gj6XSMlcROJSWIZSCnefD2wsoup3wHVA8k+E/sBUT1gANDGz1kAfIMvdN7r7JiAL6BvqGrn7Ak/ctjoVGJB0rClhe0pSvFhK5iISFS9MvZhZppktTiqZpR3fzPoDue7+912q2gKrkj7nhFhJ8Zwi4gAt3X1N2F4LtCztvHQBVETiUoYLoO4+AZiQanszqwfcSGKKZa9wdzezUueENDIXkaiUZWReDocA7YG/m9lnQAbwVzNrBeQC7ZLaZoRYSfGMIuIAeWEahvDnutJOTMlcRKLi+amXMh/b/QN3P8DdD3L3g0hMjXR297XALGBYWNXSHdgSpkrmAL3NrGm48NkbmBPqtppZ97CKZRgwM3Q1C9i56mV4UrxYmmYRkahU5vuczWwacBLQ3MxygLHuPrGY5i8CpwLZwFfA+QDuvtHMbgMWhXa3uvvOi6qXklgxsx/wUigAdwFPmdlIYAUwuNRz3dPP/t2xYXntvB1LStQw46SqPgWphrZtW2kVPUZejxNTzjkt571R4f6qC43MRSQuHk1+LhMlcxGJSmVOs9QkSuYiEhUv1MhcRKTGKyxQMhcRqfE0zSIiEgFNs4iIRGAPr7autpTMRSQqGpmLiERAF0BFRCKgkbmISARcd4CKiNR8WpooIhKBQo3MRURqPk2ziIhEQKtZREQioNUsIiIR0Jy5iEgENGcuIhIBPZtFRCQCmmYREYlAYS29AJpW1ScgIlKZCt1SLqUxs0lmts7MPkyK/cbMPjGz983sOTNrklQ32syyzexTM+uTFO8bYtlmdkNSvL2ZLQzxGWZWN8T3DZ+zQ/1BpZ6r7+EJpvS6bWvpDJaU5D8rXqnqU5BqaJ/Wh1d4WL2o7cCUc85/5T5XYn9mdgLwJTDV3Y8Ksd7Aa+6eb2Z3A7j79WZ2BDANOBZoA7wCHBoO9Q/gFCAHWAQMdfePzOwp4Fl3n25mjwJ/d/dHzOxS4AfufrGZDQEGuvvZJZ2rRuYiEpXKHJm7+3xg4y6xue6eHz4uADLCdn9gurt/7e7/ArJJJPZjgWx3X+7u24HpQH8zM6An8HTYfwowIOlYU8L200Cv0L5YSuYiEhUvQzGzTDNbnFQyy9jdBcBLYbstsCqpLifEiovvD2xO+sGwM/6dY4X6LaF9sXQBVESiUlCY+hjV3ScAE8rTj5mNAfKBJ8uzf2VTMheRqOyNJ+Ca2QjgZ0Av//bCYy7QLqlZRohRTPxzoImZpYfRd3L7ncfKMbN0oHFoXyxNs4hIVBxLuZSHmfUFrgPOcPevkqpmAUPCSpT2QEfgXRIXPDuGlSt1gSHArPBDYB4wKOw/HJiZdKzhYXsQiQuuJV7Y1chcRKJSWInr58xsGnAS0NzMcoCxwGhgXyArXJNc4O4Xu/vSsDrlIxLTL5e5e0E4zuXAHKAOMMndl4Yurgemm9k44D1gYohPBB43s2wSF2CHlHquWpooVUFLE6UolbE08bWWg1POOT3znormDiONzEUkKuWdPqnplMxFJCoFSuYiIjVfLX2fs5K5iMRFyVxEJAKaMxcRiUAtfQKukrmIxKVQI3MRkZqvoKpPoIoomYtIVApLflJstJTMRSQqtfWWcyVzEYmKliaKiERAq1lERCKg2/lFRCKgkbmISAQ0Zy4iEgGtZhERiYCmWUREIqBpFhGRCBRoZC4iUvNpZC4iEoHamszTqvoEREQqk5ehlMbMJpnZOjP7MCnWzMyyzGxZ+LNpiJuZjTezbDN738w6J+0zPLRfZmbDk+JdzOyDsM94s8RTworroyRK5iISlUJLvaRgMtB3l9gNwKvu3hF4NXwG6Ad0DCUTeAQSiRkYC3QDjgXGJiXnR4CLkvbrW0ofxVIyF5GoFJahlMbd5wMbdwn3B6aE7SnAgKT4VE9YADQxs9ZAHyDL3Te6+yYgC+gb6hq5+wJ3d2DqLscqqo9iKZmLSFQKylDMLNPMFieVzBS6aOnua8L2WqBl2G4LrEpqlxNiJcVzioiX1EexdAFURKJSlpuG3H0CMKG8fbm7m9kevek01T40MheRqFTmNEsx8sIUCeHPdSGeC7RLapcRYiXFM4qIl9RHsZTMRSQqlbmapRizgJ0rUoYDM5Piw8Kqlu7AljBVMgfobWZNw4XP3sCcULfVzLqHVSzDdjlWUX0US9MsIhKVwkp81JaZTQNOApqbWQ6JVSl3AU+Z2UhgBTA4NH8ROBXIBr4Czgdw941mdhuwKLS71d13XlS9lMSKmf2Al0KhhD6KpWQuIlEpqMRjufvQYqp6FdHWgcuKOc4kYFIR8cXAUUXEPy+qj5IomYtIVGrrHaBK5iISFT0CV0QkApU5Z16TKJmLSFRqZypXMheRyGjOXEQkAgW1dGyuZC4iUdHIXEQkAroAKiISgdqZypXMRSQymmYREYmALoCKiESgts6Z6xG4pUhLS2PRu3OY+dyU3eq+//22zH15Bn9dksWrWX+mbdvWFe6vadMmvPziND5e+hYvvziNJk0af6e+a5dj2PbVCs4887QK9yXlc9PdD3LCgOEMGHFlkfVbvviSK2+6k4EXXMWQi69l2fIVFe5z+/YdXHPLb+h3zsUMveRactfkAZC7Jo8uvQdz1shRnDVyFLfc+0iF+6rp9sIjcKslJfNSXHnFhXzyybIi6+65+2Yef/JpOnc5hXG338/t40anfNwTT/gxEx/73W7x66+7jNfmvcXhR/6E1+a9xfXXffsQtrS0NO68YwxZWW+U/YtIpRnQtyeP3nNzsfV/eOJpDuvQnucmPcAdo6/iroceS/nYuWvyGHHVmN3iz76YRaMGDXjpT49y3qAzuG/C1G/q2rVpxTMT7+eZifcz9ppLyvZlIlSIp1xiomRegrZtW3Nqv15MmjStyPrDD+/IvHlvAzDv9bc54/Te39Rd84uL+cs7L/DXJVmMvfmalPs8/fQ+TH38zwBMffzPnHHGty8Gv/yyC3j2uRdYt/7z8nwdqSRdjzmSxg0bFFv/zxWr6Nb5aAAOPjCD3LXr2LBxMwDPz32dIRdfG0bRv6egILUHtr729rv079sDgN4nHsfCJe+TeOKq7GovvGmoWlIyL8F9997CDaPHUVhY9H/299//iIED+gEwYEA/GjVqSLNmTTnl5BPo0KE9Pz7uNLp07U3nH/2An/6kW0p9tjygOWvXJt4QtXbtOloe0ByANm1aMaB/Xx7936kl7S7VQKdDDuKV+QsA+ODjf7Bm7Xry1m/gnytW8fK8t3j8oTt5ZuL9pKWlMfuV+Skdc936jbRqkfi7kJ5ehwYN6rF5yxcA5K7NY9CFVzPiqjEseX/pnvlSNYiX4Z+YlPsCqJmd7+5/LKYuE8gEsDqNSUurX95uqsxpp57MunUb+Ot7H3DiCT8uss1119/G+AfGMWzYYN58cwE5OWsoKCjglJNP5JSTT2TxorkANKhfjw4d2vPmWwt5563nqbvvvjSoX49mzZp80+bGG29nbhHTJztHX/fdewujb7xDo7Ea4MJzzuKuBx/jrJGj6HjwgRzW8WDqpKWxcMn7fPSPfzLkf34JwNfbt9MsXBO58qY7yV2Tx478fNbkbeCskaMAOHfQ6QzsV/w7Clrs34ysGX+gSeNGLP00mytvupOZkx+kQf16e/x7VldazVJ2twBFJvPkN16n121bI//NHndcV07/WW/69e3J9763L40aNWTK5PEMT7rotWZNHj8ffBEA9evX48yBp7Fly1bMjLvveYg/PPbE7sf9yelAYs582LDBjLzw6u/U563bQKtWB7B27TpatTrgmymVLp1/wJNP/B6A5s2b0a9vT/Lz85k1a84e+f5Sfg3q12PcDYm/J+5OnyGZZLRpxZIPPuKMPj25OvO83fYZH6635K7JY8xd45n8wO3fqT+gRTPWrt9AqwOak59fwJdffkWTxg0xM+rW3QeAIzt1oF2bVny2ajVHHdZhD3/L6iu26ZNUlTjNYmbvF1M+AFrupXOsEmNuuouDDu5Kh0O789/nXsq8eW9/J5ED7L9/UxLvYYUbrr+CyVOmAzA363XOH3E29cPoqE2bVrRosX9K/c5+fi7Dzvs5AMPO+znPP59I1h07/ZgOh3anw6HdeebZF7j8yhuVyKuprV98yY4dOwB45oUsuhxzJA3q16N752PIeuMdPt+0GYAtW79g9dpSX7oOQI/jjmXmy/MAmPvGO3TrfDRmxsbNW76Zd1+1ei0rc9fQrk3U/2uWqtA95RKT0kbmLYE+wKZd4ga8s0fOqJr79dhfsnjJ35k9O4sTTzyO228bjeO8+eYCrrgysQoh65X5HHZYR956cxYA//7yK4aNuIL1KVy4vPs3DzP9T49y/oihrFyZw5BzLt6j30fK7tpb72XR3z5k85at9Bo0kkvPH0J+fiKhnt2/L8tX5jDmzvGYwSEHfZ9br7scgEMOascVI/+bzF/+mkJ39kmvw5ir/oc2rQ4otc8zTz2Z0XfcT79zLqZxo4b8JlxUX/L3pTz0x2mk16lDWloaN/8iUV+bxZWiU2clzcGa2UTgj+7+VhF1f3L3c0rroKZOs8ie9Z8Vr1T1KUg1tE/rwyv80rdzDhyYcs7504rnonnJXInTLO4+sqhEHupKTeQiIntbZa5mMbOrzWypmX1oZtPM7Htm1t7MFppZtpnNMLO6oe2+4XN2qD8o6TijQ/xTM+uTFO8bYtlmdkNFvreWJopIVPLxlEtJzKwtcCXQ1d2PAuoAQ4C7gd+5ewcSU9Ajwy4jgU0h/rvQDjM7Iux3JNAX+L2Z1TGzOsDDQD/gCGBoaFsuSuYiEpVKXmeeDuxnZulAPWAN0BN4OtRPAQaE7f7hM6G+lyVWSPQHprv71+7+LyAbODaUbHdf7u7bgemhbbkomYtIVMpyB6iZZZrZ4qSSufM47p4L/BZYSSKJbwGWAJvdPT80ywHahu22wKqwb35ov39yfJd9iouXi56aKCJRKcuNdcn3xOzKzJqSGCm3BzYDfyYxTVItKZmLSFQq8QFaJwP/cvf1AGb2LHA80MTM0sPoOwPIDe1zgXZATpiWaQx8nhTfKXmf4uJlpmkWEYlKAZ5yKcVKoLuZ1Qtz372Aj4B5wKDQZjgwM2zPCp8J9a954teEWcCQsNqlPdAReBdYBHQMq2PqkrhIOqu831sjcxGJSmWNzN19oZk9DfwVyAfeIzEl8wIw3czGhdjEsMtE4HEzywY2kkjOuPtSM3uKxA+CfOAydy8AMLPLgTkkVspMcvdyPymtxJuGKoNuGpKi6KYhKUpl3DTUr12/lHPOS6teiuamIY3MRSQqtfVBW0rmIhKV2J5TniolcxGJSmyvg0uVkrmIRKXAa+dEi5K5iERF0ywiIhGI7aUTqVIyF5Go1M5UrmQuIpHRBVARkQgomYuIRECrWUREIqDVLCIiEdjTz5uqrpTMRSQqmjMXEYmARuYiIhEoqKXPTVQyF5Go6A5QEZEIaDWLiEgENDIXEYmARuYiIhHQyFxEJAK19Xb+tKo+ARGRyuRl+Kc0ZtbEzJ42s0/M7GMz+7GZNTOzLDNbFv5sGtqamY03s2wze9/MOicdZ3hov8zMhifFu5jZB2Gf8WZm5f3eSuYiEhX3wpRLCh4AXnb3w4BjgI+BG4BX3b0j8Gr4DNAP6BhKJvAIgJk1A8YC3YBjgbE7fwCENhcl7de3vN9byVxEolKIp1xKYmaNgROAiQDuvt3dNwP9gSmh2RRgQNjuD0z1hAVAEzNrDfQBstx9o7tvArKAvqGukbsv8MRtq1OTjlVmSuYiEhV3T7mYWaaZLU4qmUmHag+sB/5oZu+Z2WNmVh9o6e5rQpu1QMuw3RZYlbR/ToiVFM8pIl4uugAqIlEpy4O23H0CMKGY6nSgM3CFuy80swf4dkpl5/5uZtVi+YxG5iISlYLCwpRLKXKAHHdfGD4/TSK554UpEsKf60J9LtAuaf+MECspnlFEvFyUzEUkKpW1msXd1wKrzKxTCPUCPgJmATtXpAwHZobtWcCwsKqlO7AlTMfMAXqbWdNw4bM3MCfUbTWz7mEVy7CkY5WZpllEJCqV/AjcK4AnzawusBw4n8Qg+CkzGwmsAAaHti8CpwLZwFehLe6+0cxuAxaFdre6+8awfSkwGdgPeCmUcrE9/ezf9Lptq8V8klQv/1nxSlWfglRD+7Q+vNzrrHdq0bhTyjln/ZZPK9xfdaGRuYhERS+nEBGJQAoXNqOkZC4iUdE7QEVEIqBpFhGRCOgRuCIiEdDLKUREIqCRuYhIBApr6csplMxFJCq6ACoiEgElcxGRCNTOVL4Xns0i3zKzzPD8ZJFv6O+FVAY9Anfvyiy9idRC+nshFaZkLiISASVzEZEIKJnvXZoXlaLo74VUmC6AiohEQCNzEZEIKJmLiERAyXwvMbO+ZvapmWWb2Q1VfT5S9cxskpmtM7MPq/pcpOZTMt8LzKwO8DDQDzgCGGpmR1TtWUk1MBnoW9UnIXFQMt87jgWy3X25u28HpgP9q/icpIq5+3xgY1Wfh8RByXzvaAusSvqcE2IiIpVCyVxEJAJK5ntHLtAu6XNGiImIVAol871jEdDRzNqbWV1gCDCris9JRCKiZL4XuHs+cDkwB/gYeMrdl1btWUlVM7NpwF+ATmaWY2Yjq/qcpObS7fwiIhHQyFxEJAJK5iIiEVAyFxGJgJK5iEgElMxFRCKgZC4iEgElcxGRCPw/n8l12oUnzJYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cf, annot=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model.joblib']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(NN, \"./model.joblib\", compress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
